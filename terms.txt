评估指标：
TP：正确检出缺陷
FP：误判为缺陷
FN：是缺陷但没检测出来（漏检）
这里T/F就是判断的对错，P/N是其预测成了什么（在这里是要判断缺陷，所以P为缺陷），如TP就是判断正确且预测为缺陷，FN就是判断错误预测为无缺陷（即其有缺陷）
Precision = TP / (TP + FP) 预测中有多少是真缺陷
Recall = TP / (TP + FN) 所有缺陷有多少被检测出来
显然准确率和召回率是成反比的，当置信度上升时，准确率会提升但召回率会下降
F1score = 2 * (Precision * Recall) / (Precision + Recall) 是一个综合指标，用于选择最优置信度阈值
IoU表示检测框和真实框的重合程度有多好，其>=0.5算一次正确检测
只有当 类别正确 + IoU >= 阈值时，才算一次正确检测（两者共同确定）

情况 1：检测到了，但框很偏
IoU = 0.3、阈值 = 0.5
❌ 不算正确检测
结果：FP +1、FN +1

情况 2：检测到了，框也准
IoU = 0.7
✅ 算正确检测
结果：TP +1

情况 3：检测到了，但类别错了
❌ 不算正确检测
结果：FP +1、FN +1

情况 4：完全没检测到
❌ 漏检
结果：FN +1

AP（Average Precision）是某一类别的P-R曲线下的面积，是Precision-Recall的综合结果，越小表示检测难度越大
mAP50是将IoU的阈值固定为0.5并对所有AP取平均
mAP50-95是将IoU的阈值从0.5到0.95（步长为0.05）所有的情况分别对AP进行计算最后总体再取平均，是更严格的指标
